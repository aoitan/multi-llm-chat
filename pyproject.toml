[project]
name = "multi-llm-chat"
version = "0.1.0"
description = "CLI and web UI frontends for chatting with Gemini and ChatGPT in a shared history."
readme = "README.md"
requires-python = ">=3.10"
authors = [
    { name = "Multi LLM Chat Contributors" },
]
dependencies = [
    "google-generativeai>=0.4",
    "gradio>=4.0,<6.0",
    "mcp>=1.0",
    "openai>=1.0",
    "python-dotenv>=1.0",
    "pyperclip>=1.8",
    "tiktoken>=0.5",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0",
    "pytest-asyncio>=0.21.0",
    "ruff>=0.4",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build]
packages = ["src/multi_llm_chat"]

[tool.ruff]
target-version = "py310"
line-length = 100
src = ["src"]
extend-include = ["tests/**"]

[tool.ruff.lint]
select = ["E", "F", "B", "I"]

[tool.ruff.lint.per-file-ignores]
"src/multi_llm_chat/core.py" = ["E402"]  # load_dotenv() before imports is intentional
"src/multi_llm_chat/llm_provider.py" = ["E402"]  # load_dotenv() before reading env vars

[tool.pytest.ini_options]
markers = [
    "smoke: lightweight startup/health checks",
    "e2e: end-to-end style tests using mocked providers",
]
