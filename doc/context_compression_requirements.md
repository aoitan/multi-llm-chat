# 新機能要件定義：コンテキスト圧縮機能

### 1. 概要

会話履歴が長くなることによる、APIのトークン数上限超過エラーの防止、APIコストの抑制、および応答速度の維持を目的として、LLMに送信するコンテキストのサイズを管理（圧縮）する機能を導入する。

### 2. 機能要件 (FR)

-   **FR-1: 最大トークン数の設定**
    -   送信するコンテキストの**最大トークン数**を設定できること。
    -   設定は、モデルごとに行えるようにする（例: `GEMINI_MAX_TOKENS`, `CHATGPT_MAX_TOKENS`）。
    -   特定のモデルに対する設定がない場合は、汎用のデフォルト値（`DEFAULT_MAX_TOKENS`）にフォールバックする。

-   **FR-2: トークン数の計算**
    -   現在の会話履歴が、選択中のモデルに対応する**最大トークン数**を超えているかどうかを判定できること。

-   **FR-3: コンテキストの枝刈り（Pruning）**
    -   トークン数が上限を超える場合、設定された圧縮方式に従って、古い会話履歴を文脈から削除し、上限内に収まるように調整すること。

-   **FR-4: システムプロンプトのトークン数チェック**
    -   システムプロンプトが、選択中のモデルの**最大トークン数**を超える場合、エラーを発生させてユーザーに通知する。

-   **FR-5: 単一ターンの超過処理**
    -   システムプロンプトと最新の会話ターン（ユーザー発言とAI応答のペア）だけで**最大トークン数**を超える場合、その旨をUI上でユーザーに通知し、APIへの送信を中止する。

### 3. 非機能要件 (NFR)

-   **NFR-1: トークナイザの拡張性**
    -   トークン数計算ロジックは、将来的にAnthropic/Claudeなど新しいモデルプロバイダの公式トークナイザを簡単に追加・差し替えできるよう、プロバイダ名をキーとしたディクショナリなどで管理し、プラガブルな設計とすること。
    -   概算によるトークン数と、API返却値に含まれる実際のトークン数の差を監視し、乖離が20%以上続く場合は警告ログを出力する仕組みを設ける。

### 4. 圧縮方式の検討

圧縮方式には、それぞれ利点と欠点があります。実装の複雑さ、コスト、文脈保持能力のトレードオフを考慮して選択します。

-   **方式A: スライディングウィンドウ**
    -   **方法**: 常に最新の会話履歴を、設定された**最大トークン数**の上限に収まるように保持する。
    -   **長所**: 実装が非常にシンプル。直近の文脈は完全に保持される。
    -   **短所**: 会話の序盤で行った重要な指示や設定を忘れてしまう。

-   **方式B: 要約**
    -   **方法**: 古くなった会話履歴を、別のLLM（より安価で高速なモデル）を使って要約し、要約文で置き換える。
    -   **長所**: 会話全体の情報を（圧縮された形で）保持できる。
    -   **短所**: 要約処理自体にAPIコストと時間がかかる。要約の過程で重要なディテールが失われる可能性がある。

-   **方式C: ハイブリッド（要約＋スライディングウィンドウ）**
    -   **方法**: 会話の冒頭部分や重要な指示を「サマリー」として常に保持しつつ、直近の会話は「スライディングウィンドウ」でそのまま保持する。`コンテキスト = サマリー + 直近の会話` という構成。
    -   **長所**: 長期的な記憶と、直近の詳細な文脈の両方を維持できる可能性がある。
    -   **短所**: 実装が最も複雑になり、要約のタイミングや内容を管理するロジックが必要。

### 5. MVP設計提案

まずは、機能の恩恵を最も早く、かつシンプルに実現できる方法から着手することを提案します。

-   **設定方法**:
    -   `CHATGPT_MAX_TOKENS`、`GEMINI_MAX_TOKENS` のような命名規則で、モデルごとの**最大トークン数**を環境変数で設定可能にする。設定されていない場合は、安全なデフォルト値（例: 4096）にフォールバックする。

-   **トークン計算方法**:
    -   プロバイダごとにトークン計算関数を管理する仕組みを導入する。
    -   **OpenAI**: `tiktoken` ライブラリを使用する。
    -   **その他 (Gemini, Claude等)**: MVP段階では、各言語で一般的に安全側とされる係数（日本語: 文字数 * 2.0, 英語: 文字数 / 4）を用いた概算で一時的に対応する。この係数は内部設定とし、概算が不正確であるリスクはUI上でユーザーに通知する。

-   **圧縮方式**:
    -   MVPでは、最もシンプルで効果的な**方式A: スライディングウィンドウ**を採用する。
    -   実装としては、常にシステムプロンプト（もしあれば）を保持し、合計トークン数が上限を超える場合は、上限内に収まるまで古い会話のやり取り（ユーザー発言とAI応答のペア）から順に削除する。

### 6. エラーハンドリング

-   **APIエラー**: API呼び出し時にトークン数上限エラーが返却された場合、その旨をユーザーに通知し、コンテキストを手動で編集・短縮するよう促す。
-   **設定エラー**: 環境変数で設定された**最大トークン数**が不正な値（数値以外など）の場合、アプリケーション起動時にエラーログを出力し、デフォルト値で動作する。

### 7. 将来の展望

-   MVPリリース後、ユーザーのフィードバックや利用状況に応じて、より高度な**方式C: ハイブリッド（要約＋スライディングウィンドウ）**の実装を検討する。
-   各モデルプロバイダの公式トークナイザを順次導入し、トークン計算の精度を向上させる。
