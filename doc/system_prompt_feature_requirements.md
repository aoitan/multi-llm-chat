# 全体リファクタリングと新機能要件定義：システムプロンプト設定機能

### 1. 概要

今後の機能拡張を見据え、プロジェクト全体のファイル構成をリファクタリングし、責務の分離を行う。その上で、AIの役割や応答スタイルを指示するための「システムプロンプト」を設定する機能を追加する。

### 2. 全体リファクタリング計画

現在の`app.py`と`chat_logic.py`を、以下の3つのファイルに再編成する。このリファクタリングは、他の新機能実装の前に完了させる。

-   `core.py` (新設)
    -   **役割**: アプリケーションの核となる、UIに依存しない共通ロジックを格納する。
    -   **主な内容**:
        -   APIキーの読み込み。
        -   モデルインスタンスの管理（キャッシュと再初期化）。
        -   モデルごとのAPI呼び出しラッパー (`call_llm_api`のような統一インターフェースを想定)。
        -   APIリクエスト構築処理（履歴フォーマット、コンテキスト圧縮、システムプロンプト適用）。
        -   トークン数計算など、UIとCLIで共有されるビジネスロジック。

-   `webui.py` (`app.py`からリネーム)
    -   **役割**: Gradioを使ったWeb UIの実装に特化する。アプリケーションのエントリーポイント。
    -   **起動方法**: `python webui.py`

-   `cli.py` (`chat_logic.py`から分離)
    -   **役割**: コマンドラインインターフェース（CLI）の実装に特化する。アプリケーションのエントリーポイント。
    -   **起動方法**: `python cli.py`

#### `chat_logic.py` からの機能移行マッピング

| 旧ファイル (`chat_logic.py`) | 新ファイル | 備考 |
| :--- | :--- | :--- |
| `load_api_key` | `core.py` | |
| `call_gemini_api` | `core.py` | `call_llm_api`等の統一インターフェースに統合 |
| `call_chatgpt_api` | `core.py` | `call_llm_api`等の統一インターフェースに統合 |
| `format_history` | `core.py` | |
| `main` (対話ループ) | `cli.py` | |
| `test_chat_logic.py` | `tests/test_core.py`, `tests/test_cli.py` | 新しいファイル構成に合わせてテストも再編成する |

この再編成により、`chat_logic.py`と`test_chat_logic.py`は新しいファイルに置き換えられ、削除される。

### 3. システムプロンプト機能 要件定義

-   **FR-1: システムプロンプトの適用**
    -   ユーザーは、会話の**セッションごと**にAIの役割や応答の前提条件を「システムプロンプト」として設定できる。
    -   設定されたシステムプロンプトは、APIに送信される会話履歴の先頭に、各モデルに適した形式で挿入される。
    -   設定されたシステムプロンプトは、コンテキスト圧縮による枝刈りの対象外とする。（`context_compression_requirements.md`参照）

-   **FR-2: Web UIでの設定**
    -   Web UIに、複数行入力可能なテキストボックスを設置し、ユーザーがシステムプロンプトを入力・編集できるようにする。
    -   入力されたシステムプロンプトのトークン数を計算し、上限（`context_compression_requirements.md`で定義されたモデルごとの**最大コンテキスト長**）を超える場合はUI上で「警告: トークン数が上限を超えています」のように赤字で警告を表示し、送信ボタンを無効化すること。

-   **FR-3: CLIでの設定**
    -   CLIに、システムプロンプトを管理するための特別なコマンド群を導入する。将来的な `/history` や `/config` 等のコマンド追加を見据え、`/`で始まるコマンド体系とする。
    -   **コマンド体系**:
        -   `/system <プロンプト内容>`: システムプロンプトを設定・変更する。
        -   `/system`: 現在のシステムプロンプトを表示する。
        -   `/system clear`: 設定を解除する。
    -   コマンド実行時にトークン数を計算し、上限（`context_compression_requirements.md`で定義されたモデルごとの**最大コンテキスト長**）を超える場合は「警告: トークン数が上限を超えています。設定できません。」というメッセージを表示して処理を中断すること。

-   **FR-4: 永続性と復元**
    -   設定されたシステムプロンプトは、会話履歴の保存時に共に永続化される。（`history_feature_requirements.md`参照）
    -   保存された会話履歴を読み込む際、システムプロンプトもUI/CLIに復元され、現在のセッションのシステムプロンプトを上書きする。
    -   「新規会話を開始」する際、現在のシステムプロンプトはクリアせず、維持される仕様とする。将来的には、クリアするかどうかを選択できるUIの導入を検討する。

### 4. MVP設計提案

-   **`core.py`**:
    -   `get_token_info(text, model_name)`: 指定されたテキストのトークン数、モデルの**最大コンテキスト長**、および計算が概算かどうかのフラグ (`is_estimated`) を含む辞書を返すインターフェースを設ける。UI/CLIはこのAPIを呼び出す。
    -   `prepare_request(history, system_prompt, model_name)`: モデルに応じてシステムプロンプトの適用や履歴のフォーマットを行う。
        -   **OpenAIの場合**: `history` リストの先頭に `{'role': 'system', 'content': ...}` を追加したリストを返す。
        -   **Geminiの場合**: `system_prompt`文字列と整形済み`history`をタプル `(system_prompt, history)` として返す。呼び出し側は、`system_prompt`が変更されたことを検知した場合、`GenerativeModel(model_name, system_instruction=...)` のようにモデルを再初期化する必要がある。
        -   **その他 (Claude等)**: 将来の拡張性を考慮し、`model_name`に基づいて処理を分岐できる構造にする。

-   **`webui.py`**:
    -   `gr.Textbox(lines=3, label="System Prompt")` をUI上部に追加する。
    -   テキストボックスの下に、現在の入力トークン数と選択中モデルの**最大コンテキスト長**を表示する `gr.Markdown` を追加する（例: `Tokens: 128 / 8192 (estimated)`）。
    -   テキストが変更されるたびに `core.py` の `get_token_info` を呼び出し、表示を更新する。上限を超えた場合は、警告色（赤など）で表示し、送信ボタンを無効化する。

-   **`cli.py`**:
    -   `/system` コマンド体系を実装する。
    -   設定/変更時、`core.py` の `get_token_info` を呼び出し、上限を超える場合は警告を表示して設定を拒否する。

### 5. エラーハンドリング
-   **APIエラー**: API呼び出しに失敗した場合（認証エラー、タイムアウト、サーバーエラー等）、その旨をログに出力し、UI/CLI上で「APIエラー: <エラー種別>: <エラーメッセージ>」といった具体的なメッセージをユーザーに表示する。
-   **不正なコマンド**: CLIで未定義のコマンドが入力された場合、「エラー: `/<コマンド名>` は不明なコマンドです。利用可能なコマンドは `/system` などです。」と表示する。
