# 全体リファクタリングと新機能要件定義：システムプロンプト設定機能

### 1. 概要

今後の機能拡張を見据え、プロジェクト全体のファイル構成をリファクタリングし、責務の分離を行う。その上で、AIの役割や応答スタイルを指示するための「システムプロンプト」を設定する機能を追加する。

### 2. 全体リファクタリング計画

現在の`app.py`と`chat_logic.py`を、以下の3つのファイルに再編成する。このリファクタリングは、他の新機能実装の前に完了させる。

-   `core.py` (新設)
    -   **役割**: アプリケーションの核となる、UIに依存しない共通ロジックを格納する。
    -   **主な内容**:
        -   APIキーの読み込み。
        -   モデルごとのAPI呼び出しラッパー (`call_llm_api`のような統一インターフェースを想定)。
        -   APIリクエスト構築処理（履歴フォーマット、コンテキスト圧縮、システムプロンプト適用）。
        -   トークン数計算など、UIとCLIで共有されるビジネスロジック。

-   `webui.py` (`app.py`からリネーム)
    -   **役割**: Gradioを使ったWeb UIの実装に特化する。アプリケーションのエントリーポイント。
    -   **起動方法**: `python webui.py`

-   `cli.py` (`chat_logic.py`から分離)
    -   **役割**: コマンドラインインターフェース（CLI）の実装に特化する。アプリケーションのエントリーポイント。
    -   **起動方法**: `python cli.py`

#### `chat_logic.py` からの機能移行マッピング

| 旧ファイル (`chat_logic.py`) | 新ファイル | 備考 |
| :--- | :--- | :--- |
| `load_api_key` | `core.py` | |
| `call_gemini_api` | `core.py` | `call_llm_api`等の統一インターフェースに統合 |
| `call_chatgpt_api` | `core.py` | `call_llm_api`等の統一インターフェースに統合 |
| `format_history` | `core.py` | |
| `main` (対話ループ) | `cli.py` | |
| `test_*.py`内の関連テスト | `tests/test_core.py`等 | 新しいファイル構成に合わせてテストも再編成する |

この再編成により、`chat_logic.py`は`core.py`と`cli.py`に分割され、削除される。

### 3. システムプロンプト機能 要件定義

-   **FR-1: システムプロンプトの適用**
    -   ユーザーは、会話の**セッションごと**にAIの役割や応答の前提条件を「システムプロンプト」として設定できる。
    -   設定されたシステムプロンプトは、APIに送信される会話履歴の先頭に、各モデルに適した形式で挿入される。
    -   設定されたシステムプロンプトは、コンテキスト圧縮による枝刈りの対象外とする。（`context_compression_requirements.md`参照）

-   **FR-2: Web UIでの設定**
    -   Web UIに、複数行入力可能なテキストボックスを設置し、ユーザーがシステムプロンプトを入力・編集できるようにする。
    -   入力されたシステムプロンプトのトークン数を計算し、上限（`context_compression_requirements.md`で定義されたモデルごとの**最大コンテキスト長**）を超える場合はUI上で警告を表示し、送信を不可にすること。

-   **FR-3: CLIでの設定**
    -   CLIに、システムプロンプトを設定・変更・解除するための特別なコマンドを導入する。
    -   **コマンド体系**:
        -   `/system <プロンプト内容>`: システムプロンプトを設定・変更する。
        -   `/system`: 現在のシステムプロンプトを表示する。
        -   `/system clear`: 設定を解除する。
    -   コマンド実行時にトークン数を計算し、上限（`context_compression_requirements.md`で定義されたモデルごとの**最大コンテキスト長**）を超える場合は警告メッセージを表示すること。

-   **FR-4: 永続性と復元**
    -   設定されたシステムプロンプトは、会話履歴の保存時に共に永続化される。（`history_feature_requirements.md`参照）
    -   保存された会話履歴を読み込む際、システムプロンプトもUI/CLIに復元され、セッションに適用される。
    -   「新規会話を開始」する際、現在のシステムプロンプトは維持するか、クリアするかを選択できる（MVPでは維持する仕様とする）。

### 4. MVP設計提案

-   **`core.py`**:
    -   `get_token_count_info(text, model_name)`: 指定されたテキストのトークン数、モデルの**最大コンテキスト長**、概算かどうかのフラグを返すインターフェースを設ける。UI/CLIはこのAPIを呼び出す。
    -   `prepare_request(history, system_prompt, model_name)`: モデルに応じてシステムプロンプトの適用や履歴のフォーマットを行う。
        -   **OpenAIの場合**: `history` リストの先頭に `{'role': 'system', 'content': ...}` を追加したリストを返す。
        -   **Geminiの場合**: `system_prompt`文字列と整形済み`history`を別々に返す。呼び出し側は `GenerativeModel(model_name, system_instruction=...)` のようにモデルを初期化する。この際、プロンプトが変更されるたびにモデルインスタンスが再生成されることに留意する。
        -   **その他 (Claude等)**: 将来の拡張性を考慮し、`model_name`に基づいて処理を分岐できる構造にする。

-   **`webui.py`**:
    -   `gr.Textbox(lines=3, label="System Prompt")` をUI上部に追加する。
    -   テキストボックスの下に、現在の入力トークン数と選択中モデルの**最大コンテキスト長**を表示する `gr.Markdown` を追加する（例: `Tokens: 128 / 8192 (estimated)`）。
    -   テキストが変更されるたびに `core.py` の `get_token_count_info` を呼び出し、表示を更新する。上限を超えた場合は、警告色で表示し、送信ボタンを無効化する。

-   **`cli.py`**:
    -   `/system` コマンド体系を実装する。
    -   設定/変更時、`core.py` の `get_token_count_info` を呼び出し、上限を超える場合は警告を表示して設定を拒否する。

### 5. エラーハンドリング
-   **APIエラー**: API呼び出しに失敗した場合（認証エラー、タイムアウト等）、その旨をログに出力し、UI/CLI上で「APIエラー: <エラー詳細>」といったメッセージをユーザーに表示する。
-   **不正なコマンド**: CLIで未定義のコマンドが入力された場合、「エラー: `/<コマンド名>` は不明なコマンドです」と表示する。
