# 全体リファクタリングと新機能要件定義：システムプロンプト設定機能

### 1. 概要

今後の機能拡張を見据え、プロジェクト全体のファイル構成をリファクタリングし、責務の分離を行う。その上で、AIの役割や応答スタイルを指示するための「システムプロンプト」を設定する機能を追加する。

### 2. 全体リファクタリング計画

現在の`app.py`と`chat_logic.py`を、以下の3つのファイルに再編成する。このリファクタリングは、システムプロンプト機能の実装前に行う。

-   `core.py` (新設)
    -   **役割**: アプリケーションの核となる、UIに依存しない共通ロジックを格納する。
    -   **主な内容**:
        -   APIキーの読み込み
        -   モデルごとのAPI呼び出しラッパー (`call_llm_api`のような統一インターフェースを想定)
        -   履歴フォーマット、コンテキスト圧縮、システムプロンプト適用など、APIリクエストを組み立てる一連の処理。

-   `webui.py` (`app.py`からリネーム)
    -   **役割**: Gradioを使ったWeb UIの実装に特化する。
    -   **主な内容**:
        -   Gradioコンポーネントの定義とレイアウト
        -   UIイベント（ボタンクリックなど）のハンドリング
        -   `core.py`の関数を呼び出して、UIを更新する

-   `cli.py` (`chat_logic.py`から分離)
    -   **役割**: コマンドラインインターフェース（CLI）の実装に特化する。
    -   **主な内容**:
        -   `input()` を使った対話ループ
        -   ユーザー入力の解析
        -   `core.py`の関数を呼び出して、結果をコンソールに表示する

#### `chat_logic.py` からの機能移行マッピング

| 旧ファイル (`chat_logic.py`) | 新ファイル | 備考 |
| :--- | :--- | :--- |
| `load_api_key` | `core.py` | |
| `call_gemini_api` | `core.py` | 統一APIラッパーに統合 |
| `call_chatgpt_api` | `core.py` | 統一APIラッパーに統合 |
| `format_history` | `core.py` | |
| `main` (対話ループ) | `cli.py` | |

この再編成により、`chat_logic.py`は`core.py`と`cli.py`に分割され、削除される。

### 3. システムプロンプト機能 要件定義

-   **FR-1: システムプロンプトの適用**
    -   ユーザーは、会話の開始時にAIの役割や応答の前提条件（例: 「あなたはプロの翻訳家です」「JSON形式で応答してください」）を「システムプロンプト」として設定できる。
    -   設定されたシステムプロンプトは、APIに送信される会話履歴の先頭に、各モデルに適した形式で挿入される。
    -   設定されたシステムプロンプトは、コンテキスト圧縮による枝刈りの対象外とする。（`context_compression_requirements.md`参照）

-   **FR-2: Web UIでの設定**
    -   Web UIに、複数行入力可能なテキストボックスを設置し、ユーザーがセッションごとにシステムプロンプトを入力・編集できるようにする。
    -   入力されたシステムプロンプトのトークン数を計算し、上限（`context_compression_requirements.md`で定義されたモデルごとの**最大トークン数**）を超える場合はUI上で警告を表示し、送信を不可にするなどのバリデーションを行うこと。

-   **FR-3: CLIでの設定**
    -   CLIに、システムプロンプトを設定・変更するための特別なコマンド（例: `/system <プロンプト内容>`）を導入する。
    -   `/system` のようにプロンプト内容を空にしてコマンドを実行した場合、システムプロンプトを解除する。
    -   コマンド実行時にトークン数を計算し、上限（`context_compression_requirements.md`で定義されたモデルごとの**最大トークン数**）を超える場合は警告メッセージを表示すること。

### 4. MVP設計提案

-   **`core.py`**:
    -   `apply_system_prompt(history, system_prompt, model_name)` のような、モデルに応じてシステムプロンプトを適用するためのロジックを実装する。このロジックは、モデルごとに異なる形式の出力を返す。
        -   **OpenAIの場合**: `history` リストの先頭に `{'role': 'system', 'content': ...}` を追加した新しい `history` リストを返す。
        -   **Geminiの場合**: `system_prompt` の文字列そのものを返し、API呼び出し側が `GenerativeModel(model_name, system_instruction=...)` のようにモデルを初期化できるようにする。
        -   **その他 (Claude等)**: 将来の拡張性を考慮し、`model_name`に基づいて処理を分岐できる構造にする。

-   **`webui.py`**:
    -   `gr.Textbox(lines=3, label="System Prompt")` をUI上部に追加する。
    -   テキストボックスの下に、現在の入力トークン数と選択中モデルの**最大トークン数**を表示する `gr.Markdown` を追加する（例: `Token count: 128 / 8192`）。
    -   テキストが変更されるたびにトークン数を再計算し、表示を更新する。上限を超えた場合は、警告色で表示し、送信ボタンを無効化する。

-   **`cli.py`**:
    -   対話ループの中で、ユーザー入力が `/` で始まる場合は、それをコマンドとして解釈するロジックを追加する。
    -   `/system` コマンドが実行された際、設定されたプロンプトのトークン数を計算し、上限を超える場合は警告を表示して設定を拒否する。

### 5. エラーハンドリング
-   **APIエラー**: API呼び出しに失敗した場合（認証エラー、タイムアウト等）、その旨をログに出力し、UI/CLI上でユーザーにエラーメッセージを表示する。
