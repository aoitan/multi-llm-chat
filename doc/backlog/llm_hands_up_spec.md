# 挙手制・自律応答判定 機能仕様案

## 背景と目的
- デフォルトは「黙る」（メンション時のみ応答）を維持しつつ、各LLMが「発言したい」意思を表明できる挙手制を導入する。
- 無限LLM会話やノイズを防ぎ、ユーザーが司会権限を持ったまま多モデルの視点を活用する。
- 本回答を投げる前にフィルタリングすることでトークンコストを抑え、関連性・有用性の高い発言だけを生成させる。

## 用語
- will判定: モデルが自発的に話すべきかを0〜1で評価すること。
- 挙手（hand raise）: will判定の結果が閾値以上のときに、UIに「発言したい」カードを表示すること。
- オーケストレーター: will判定を行う役割。軽量LLM、各モデル自身の自己判定、または両者を組み合わせたハイブリッドを想定。

## 機能要件（概要）
- will判定フェーズを本回答生成前に挟む。
  - 入力: 直近コンテキスト＋各モデルのプロファイル（得意分野・ロールなど）。
  - 出力: `{model, will (0.0-1.0), reason (短文)}`。
- UIに挙手カードを表示し、ユーザーが「発言させる」「スキップ」を選択できる。
  - バッチ操作: 「全員許可」「全員スキップ」「will>=Xを自動許可」。
- 本回答は許可されたモデルのみに送信し、未許可モデルはSKIPとして記録。
- モード切り替え:
  - 集中モード: 挙手表示→ユーザー承認必須（デフォルト）。
  - ブレストモード: willが低めでも自動許可（例: will>0.3で自動許可、上限人数あり）。
  - メンション専用モード: 現行と同じ（will判定を行わずメンション時のみ応答）。
- クールダウン: 直近で多く発言したモデルのwillに減衰をかける（例: 1ターンごとに-0.1、下限0）。
- @all併用: @all時もwill判定を行い、挙手カードを出す。全許可ボタンで従来挙動に近づける。

## 判定方式
- A) 軽量ジャッジモデル方式（推奨デフォルト）
  - 長所: 本番モデルのトークン消費なし、ポリシー差し替え容易。
  - 短所: ジャッジ精度に依存、コンテキストをどこまで渡すか設計が必要。
- B) 各モデルの自己判定方式
  - 2段階: 先に `RESPOND/SKIP + will + reason` を出させ、RESPONDなら本回答生成。
  - 長所: モデル固有の主観を反映しやすい。
  - 短所: トークンコスト増、常にRESPONDしがちバイアスへの補正が必要。
- ハイブリッド
  - ジャッジでフィルタした後、各モデルにも軽量自己判定を投げて最終willを確定。

### willスコア例
```
relevance: 話題と専門の関連度 (0〜1)
novelty: 既出回答に対する新規性 (0〜1)
confidence: 知識の確かさ (0〜1)
will = 0.5*relevance + 0.3*novelty + 0.2*confidence
```
- 閾値デフォルト: 0.6（設定で変更可能）。
- willの偏り対策: 常時0.9などの挙手過多を検知したら自動減衰・正規化を行う。

## フロー（標準モード）
1. ユーザーメッセージ受信。
2. will判定フェーズ（軽量LLM or 自己判定 or ハイブリッド）。
3. 挙手カードをUI表示（アイコン＋モデル名＋will数値＋理由1行）。
4. ユーザーが許可/スキップを選択（複数選択可、バッチ操作あり）。
5. 許可されたモデルのみ本回答を生成。
6. 回答を表示。スキップしたモデルはログに `SKIP (will=..., reason=...)` を残す。

## UI要件
- 挙手カード例: `🙋 ChatGPTが発言したがっています (will: 0.85, 理由: 別の実装案)`
- ボタン: 「発言させる」「今回はスキップ」。
- バッチ: 「全員許可」「全員スキップ」「will>=X自動許可」。
- ステータス表示: スキップ理由を履歴/ログに簡易表示。詳細はテレメトリに残す。
- 拡張余地: 👍同意、🙅反対、❓質問など反応種別を将来追加できる設計。

## 設定項目（想定）
- will閾値（デフォルト0.6）。
- モード選択（集中/ブレスト/メンション専用）。
- クールダウン有効/無効と強さ。
- 自動許可の上限人数。
- 判定方式（オーケストレーターLLM/自己判定/ハイブリッド）。
- 挙手カードのタイムアウト（一定時間で自動スキップ or 自動許可）。

## ログ/テレメトリ
- will、reason、採否（allowed/skip）、クールダウン補正値、モード名を記録。
- 過剰挙手を検知するためのwill分布とヒストリーを保存（集計・分析用）。
- ユーザー表示は簡易にしつつ、詳細はデバッグ/分析向けに保持。

## 安全・コスト配慮
- 判定プロンプトは短文に抑え、ジャッジはローカル/安価モデルを優先。
- 本回答は許可されたモデルのみ生成してトークン節約。
- 無限ループ防止: 1ターンでの挙手→許可→回答の1サイクルのみを有効にし、追加挙手は無効または回数制限。

## 未決定事項・検討ポイント
- ジャッジモデルの候補と評価軸（ローカルLLM vs 外部API、速度/コスト/精度）。
- 判定に与えるコンテキスト量の上限と切り出し戦略（直近数ターン、要約、重要文抽出など）。
- willスコアの初期パラメータと自動調整ロジック（正規化、バイアス抑制）。
- UI上の操作ステップを減らすための自動許可ポリシーの初期値。

## 作業工程・検証計画（目安）
- 仕様確定: 0.5d — 本ドキュメントレビューとパラメータの合意。
- ジャッジモデル選定実験: 1.5〜2d
  - 候補モデル準備（ローカル軽量モデル＋1〜2種のAPIモデル）。
  - ベンチ用ダイアログ10〜20件でwillラベルのサンプルを作成し、精度/一貫性/レイテンシ/コストを計測。
  - コンテキスト長アブレーション（直近1/3/5ターン＋要約）で精度と速度を比較。
- プロンプト設計・校正: 1d
  - will算出とreason出力のプロンプト初版作成。
  - 過剰挙手（常時0.9）抑制のルール/正規化を追加して再評価。
- UIプロトタイプ: 1d
  - 挙手カードの表示・バッチ操作・タイムアウト挙動をモック実装。
- パイプライン実装（バックエンド）: 1〜1.5d
  - will判定フェーズのパイプライン挿入（集中/ブレスト/メンション専用モード切替、クールダウン処理）。
  - ログ/テレメトリ実装（SKIP理由含む）。
- テスト/QA: 1d
  - ユニット/統合テスト（判定ロジック、モード切替、ログ出力）。
  - 手動E2E: 挙手表示→許可/スキップ→回答表示の確認。
- 総計目安: 6〜7d（並行度次第で短縮可能）。

## 成果物
- 仕様ドキュメント（本書＋レビュー反映版）。
- will判定プロンプト案（ジャッジ/自己判定用）。
- 挙手UIのモック/スクリーンショット。
- 実装ブランチ: 挙手モード、設定、ログ、テストを含む。
