# API Keys (required)
GOOGLE_API_KEY=your_google_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Model Selection (optional)
GEMINI_MODEL=models/gemini-pro-latest
CHATGPT_MODEL=gpt-3.5-turbo

# Context Compression Settings (optional)
# Maximum context length per model (in tokens)
# If not set, falls back to DEFAULT_MAX_CONTEXT_LENGTH
GEMINI_MAX_CONTEXT_LENGTH=100000
CHATGPT_MAX_CONTEXT_LENGTH=50000

# Default max context length for models without specific settings
DEFAULT_MAX_CONTEXT_LENGTH=4096

# Buffer factor for token estimation (non-OpenAI models)
# Applies safety margin to estimated token counts (default: 1.2 = 20% buffer)
TOKEN_ESTIMATION_BUFFER_FACTOR=1.2

# Web UI Settings (optional)
# Set to 0.0.0.0 to share on LAN (default: 127.0.0.1)
# MLC_SERVER_NAME=0.0.0.0
